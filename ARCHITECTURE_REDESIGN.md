# Architecture Redesign: Vayo + Rough Quarters

## ğŸ¯ The Vision

**Two separate concerns, cleanly separated:**

### **Vayo = Data Acquisition Hub** ğŸ­
*"The central source for all NYC real estate data"*

- All scrapers live here
- All raw data stored here
- All data pipelines here
- Single massive database
- Reusable by ANY project

### **Rough Quarters = Discovery Intelligence** ğŸ§ 
*"Finding diamonds by querying Vayo's data"*

- NO scrapers (queries Vayo instead)
- Pure intelligence/discovery logic
- Strategies query Vayo's database
- Lightweight, focused

---

## ğŸ“Š Current State (Mixed Architecture)

**Problems:**
```
rough-quarters/
â”œâ”€â”€ diamond-finder/
â”‚   â”œâ”€â”€ strategies/
â”‚   â”‚   â”œâ”€â”€ realtor_listings_live.py    â† Reads CSV from experiments/
â”‚   â”‚   â”œâ”€â”€ building_testimonials.py    â† Has its own Reddit scraper
â”‚   â”‚   â”œâ”€â”€ discover_great_buildings.py â† Queries Vayo DB (good!)
â”‚   â””â”€â”€ ...
â””â”€â”€ experiments/
    â”œâ”€â”€ manhattan_all_listings.csv      â† Data lives here (bad!)
    â””â”€â”€ brooklyn_all_listings.csv

vayo/
â”œâ”€â”€ stuy-scrape-csv/
â”‚   â”œâ”€â”€ scrape-streeteasy.js            â† Scrapers live here
â”‚   â”œâ”€â”€ scrape-craigslist.js
â”‚   â”œâ”€â”€ scrape-reddit.js
â”‚   â””â”€â”€ stuytown.db                     â† 31.8GB database
```

**Issues:**
- Data scattered (CSVs in rough-quarters, DB in Vayo)
- Duplicate scraping logic (Reddit scraper in both places)
- rough-quarters doing too much (scraping + intelligence)

---

## ğŸ¨ Target Architecture (Clean Separation)

```
/Users/pjump/Desktop/projects/
â”‚
â”œâ”€â”€ vayo/                           â† DATA ACQUISITION HUB
â”‚   â”œâ”€â”€ scrapers/                   â† ALL scrapers here
â”‚   â”‚   â”œâ”€â”€ scrape-streeteasy.js
â”‚   â”‚   â”œâ”€â”€ scrape-realtor.js      â† Move from rough-quarters
â”‚   â”‚   â”œâ”€â”€ scrape-zillow.js       â† New
â”‚   â”‚   â”œâ”€â”€ scrape-reddit.js       â† Consolidate from rough-quarters
â”‚   â”‚   â”œâ”€â”€ scrape-craigslist.js
â”‚   â”‚   â””â”€â”€ scrape-acris.js
â”‚   â”‚
â”‚   â”œâ”€â”€ pipelines/                  â† Data processing
â”‚   â”‚   â”œâ”€â”€ geocode.py
â”‚   â”‚   â”œâ”€â”€ deduplicate.py
â”‚   â”‚   â””â”€â”€ enrich.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                       â† SINGLE SOURCE OF TRUTH
â”‚   â”‚   â””â”€â”€ vayo.db                â† Everything in ONE database
â”‚   â”‚       â”œâ”€â”€ buildings (571K)
â”‚   â”‚       â”œâ”€â”€ listings (current + historical)
â”‚   â”‚       â”œâ”€â”€ complaints (26M HPD)
â”‚   â”‚       â”œâ”€â”€ acris (16M property records)
â”‚   â”‚       â”œâ”€â”€ reddit_mentions
â”‚   â”‚       â”œâ”€â”€ rental_history
â”‚   â”‚       â””â”€â”€ ... (all data)
â”‚   â”‚
â”‚   â””â”€â”€ README.md                   â† "Vayo: NYC Real Estate Data Hub"
â”‚
â””â”€â”€ rough-quarters/                 â† DISCOVERY INTELLIGENCE
    â”œâ”€â”€ diamond-finder/
    â”‚   â”œâ”€â”€ strategies/             â† ONLY query logic (no scraping!)
    â”‚   â”‚   â”œâ”€â”€ discover_great_buildings.py
    â”‚   â”‚   â”œâ”€â”€ building_testimonials.py  â† Queries Vayo DB
    â”‚   â”‚   â”œâ”€â”€ realtor_listings.py       â† Queries Vayo DB
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â”‚
    â”‚   â”œâ”€â”€ core/
    â”‚   â”‚   â”œâ”€â”€ vayo_client.py      â† Client to query Vayo DB
    â”‚   â”‚   â”œâ”€â”€ scorer.py
    â”‚   â”‚   â””â”€â”€ database.py         â† diamonds.db (discovery results only)
    â”‚   â”‚
    â”‚   â””â”€â”€ config.yaml
    â”‚       vayo_db_path: "/Users/.../vayo/data/vayo.db"
    â”‚
    â””â”€â”€ README.md                    â† "Rough Quarters: Finding Diamonds"
```

---

## ğŸ”„ Data Flow

```
VAYO (Data Acquisition)
â”œâ”€â”€ Scrapers run daily â†’ Raw data
â”œâ”€â”€ Pipelines process â†’ Clean data
â””â”€â”€ Store in vayo.db â†’ Single source of truth
     â†“
     â†“ (SQL queries)
     â†“
ROUGH QUARTERS (Discovery Intelligence)
â”œâ”€â”€ Strategies query vayo.db
â”œâ”€â”€ Apply intelligence/scoring
â”œâ”€â”€ Find diamonds
â””â”€â”€ Store in diamonds.db (157 discoveries)
     â†“
     â†“ (HTML digest)
     â†“
USER
â””â”€â”€ Views diamonds in reports/latest.html
```

---

## ğŸš€ Migration Plan

### Phase 1: Consolidate Data in Vayo (This Week)

**Move scrapers to Vayo:**
```bash
# 1. Create vayo/scrapers/ directory
mkdir -p /Users/pjump/Desktop/projects/vayo/scrapers

# 2. Move/consolidate scrapers
# - scrape-realtor.py (new - reads Realtor CSV, loads to DB)
# - scrape-reddit.py (consolidate from rough-quarters)
# - scrape-zillow.py (new)
```

**Consolidate data into vayo.db:**
```sql
-- Add tables to vayo/data/vayo.db:
CREATE TABLE listings_current (
    -- From manhattan_all_listings.csv
    property_id TEXT,
    address TEXT,
    unit TEXT,
    price INTEGER,
    beds INTEGER,
    sqft INTEGER,
    status TEXT,
    listing_date DATE,
    ...
);

CREATE TABLE reddit_testimonials (
    -- From rough-quarters building_testimonials strategy
    building_name TEXT,
    address TEXT,
    mention_text TEXT,
    source_url TEXT,
    found_date DATE
);
```

**Benefits:**
- All data in ONE place
- Vayo becomes reusable data hub
- rough-quarters just queries it

---

### Phase 2: Update Rough Quarters to Query Vayo (Next Week)

**Create Vayo client:**
```python
# rough-quarters/diamond-finder/core/vayo_client.py

import sqlite3

class VayoClient:
    """Client to query Vayo's central data hub"""

    def __init__(self, db_path="/Users/.../vayo/data/vayo.db"):
        self.db_path = db_path

    def get_current_listings(self, address=None):
        """Get current listings from Vayo"""
        conn = sqlite3.connect(self.db_path)
        # Query listings_current table
        ...

    def get_building_testimonials(self, building_name):
        """Get Reddit testimonials from Vayo"""
        conn = sqlite3.connect(self.db_path)
        # Query reddit_testimonials table
        ...

    def get_great_buildings(self, criteria):
        """Get buildings matching criteria"""
        # Query buildings table with filters
        ...
```

**Update strategies:**
```python
# strategies/realtor_listings.py

from core.vayo_client import VayoClient

class RealtorListingsStrategy(SearchStrategy):
    def __init__(self):
        self.vayo = VayoClient()

    def search(self):
        # Query Vayo instead of reading CSV
        listings = self.vayo.get_current_listings()
        ...
```

---

### Phase 3: Vayo Becomes Production Data Hub (Month 2)

**Scheduled scraping:**
```bash
# Vayo crontab - runs all scrapers
0 2 * * * cd /path/to/vayo && node scrapers/scrape-streeteasy.js
0 3 * * * cd /path/to/vayo && python scrapers/scrape-realtor.py
0 4 * * * cd /path/to/vayo && python scrapers/scrape-reddit.py
```

**Data freshness:**
- StreetEasy: Daily
- Realtor.com: Daily
- Reddit: Daily
- ACRIS: Weekly (slow-changing)
- HPD: Monthly

**Vayo becomes:**
- Single source of truth for ALL NYC real estate data
- Reusable by other projects
- Well-maintained, scheduled updates
- Clean API for querying

---

## ğŸ“ New Directory Structure

```
vayo/
â”œâ”€â”€ README.md                       # "NYC Real Estate Data Hub"
â”œâ”€â”€ scrapers/                       # All data acquisition
â”‚   â”œâ”€â”€ scrape-streeteasy.js
â”‚   â”œâ”€â”€ scrape-realtor.py          # NEW
â”‚   â”œâ”€â”€ scrape-zillow.py           # NEW
â”‚   â”œâ”€â”€ scrape-reddit.py           # CONSOLIDATED
â”‚   â”œâ”€â”€ scrape-craigslist.js
â”‚   â””â”€â”€ scrape-acris.py
â”œâ”€â”€ pipelines/                      # Data processing
â”‚   â”œâ”€â”€ deduplicate.py
â”‚   â”œâ”€â”€ geocode.py
â”‚   â””â”€â”€ enrich.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ vayo.db                    # SINGLE DATABASE
â””â”€â”€ sql/                           # Schema definitions
    â”œâ”€â”€ create_tables.sql
    â””â”€â”€ migrations/

rough-quarters/
â”œâ”€â”€ README.md                      # "Finding Diamonds (queries Vayo)"
â””â”€â”€ diamond-finder/
    â”œâ”€â”€ strategies/                # ONLY discovery logic
    â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ vayo_client.py        # Query interface to Vayo
    â”‚   â””â”€â”€ ...
    â””â”€â”€ data/
        â””â”€â”€ diamonds.db            # Discovery results only
```

---

## ğŸ’¡ Key Benefits

### Separation of Concerns
- **Vayo:** "Get me all NYC real estate data"
- **Rough Quarters:** "Find me diamonds from that data"

### Reusability
- Other projects can use Vayo's data
- Vayo becomes central infrastructure
- rough-quarters is just one consumer

### Maintainability
- Scrapers in one place
- Data in one place
- Clear boundaries

### Scalability
- Add new scrapers to Vayo â†’ all projects benefit
- Add new discovery strategies to rough-quarters â†’ focused
- Database grows in one place

---

## ğŸ¯ First Steps (Next 1 Hour)

### 1. Create Vayo Data Hub Structure
```bash
cd /Users/pjump/Desktop/projects/vayo
mkdir -p scrapers pipelines sql data
```

### 2. Move Realtor Data to Vayo
```bash
# Copy CSV to Vayo
cp rough-quarters/experiments/*.csv vayo/data/

# Create import script
# vayo/scrapers/import-realtor-csv.py
```

### 3. Create Vayo Client in Rough Quarters
```python
# rough-quarters/diamond-finder/core/vayo_client.py
# Simple query interface
```

### 4. Update One Strategy to Use Vayo
```python
# Update realtor_listings.py to query Vayo instead of CSV
```

---

## ğŸ¤” Decision Points

**Question 1:** Keep existing vayo/stuy-scrape-csv/stuytown.db OR create new vayo/data/vayo.db?

**Options:**
- A) Use existing stuytown.db (31GB already has data)
- B) Create new vayo.db (fresh start, cleaner schema)

**Recommendation:** Use existing stuytown.db, add new tables as needed

---

**Question 2:** Move rough-quarters/experiments/ data to Vayo?

**Yes!**
```bash
mv rough-quarters/experiments/ vayo/raw-data/
# Keep rough-quarters lightweight
```

---

## ğŸ¬ Ready to Start?

**Next action:** Create Vayo hub structure and move first data source?

1. Set up vayo/scrapers/ directory
2. Move Realtor CSVs to Vayo
3. Create import script to load into vayo.db
4. Update rough-quarters to query Vayo

**Want me to start?**
