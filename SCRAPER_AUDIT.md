# Scraper Audit: Rough Quarters vs Vayo

**Date:** January 18, 2026
**Purpose:** Identify what's being scraped, where it should live, and migration plan

---

## ğŸ” Current State Analysis

### What Rough Quarters is Scraping

Let me check each strategy...

| Strategy | Scraping? | Data Source | Should Move to Vayo? |
|----------|-----------|-------------|---------------------|
| `adjacent_units.py` | âŒ No | Static analysis data | Keep (not scraping) |
| `discover_great_buildings.py` | âŒ No | Queries Vayo DB directly | âœ… Already using Vayo |
| `building_testimonials.py` | âš ï¸ YES | **Reddit scraping** | âš ï¸ **DUPLICATE** (Vayo has this!) |
| `well_maintained_buildings.py` | âŒ No | Queries HPD data | Keep (just queries) |
| `realtor_listings_live.py` | âš ï¸ Sort of | **Reads CSV file** | âš ï¸ Should import to Vayo |
| `long_tenure_simple.py` | âŒ No | Queries ACRIS | Keep (just queries) |
| `reddit_scraper_simple.py` | âš ï¸ YES | **Reddit scraping** | âš ï¸ **DUPLICATE** (Vayo has this!) |
| `lived_there_loved_it.py` | âš ï¸ YES | **Reddit scraping** | âš ï¸ **DUPLICATE** (Vayo has this!) |

**Finding:** We have 3 strategies doing Reddit scraping! Vayo already has `scrape-reddit.js`

---

### What Vayo Already Has

**Vayo's Scrapers (in `/vayo/stuy-scrape-csv/`):**

1. âœ… `scrape-reddit.js` - Reddit scraping (LIVE)
2. âœ… `scrape-streeteasy.js` - StreetEasy (LIVE)
3. âœ… `scrape-craigslist.js` - Craigslist (LIVE)
4. âœ… `scrape-facebook.js` - Facebook Marketplace (READY)
5. âœ… `scrape-dhcr.js` - Rent stabilization (LIVE)
6. âœ… `scrape-evictions.js` - Eviction data (LIVE)
7. âœ… `scrape-puppeteer.js` - Generic Puppeteer scraper (LIVE)

**Vayo's Database (stuytown.db - 30GB):**

- `buildings` (571,476 records) âœ…
- `complaints` (26,165,975 HPD records) âœ…
- `acris_real_property` (16M+ property records) âœ…
- `craigslist_listings` (889 current) âœ…
- `streeteasy_listings` (schema ready, 0 records)
- `current_rents` (rental history) âœ…
- And 30 more tables

---

## ğŸ¯ What Needs to Happen

### 1. **DUPLICATE: Reddit Scraping**

**Problem:**
- Rough Quarters has 3 Python scripts scraping Reddit
- Vayo has 1 JavaScript scraper doing the same thing

**Solution: Consolidate to Vayo**

**Keep in Vayo:**
```javascript
// vayo/stuy-scrape-csv/scrape-reddit.js
// Already working, already saving to DB
```

**Remove from Rough Quarters:**
```python
# DELETE or repurpose:
strategies/building_testimonials.py  (has Reddit scraper)
strategies/reddit_scraper_simple.py  (duplicate)
strategies/lived_there_loved_it.py   (duplicate)
```

**Replace with:**
```python
# strategies/building_testimonials.py (UPDATED)
from core.vayo_client import VayoClient

class BuildingTestimonialsStrategy:
    def search(self):
        vayo = VayoClient()
        # Query Vayo's database for Reddit data
        testimonials = vayo.get_reddit_testimonials()
        # Process and score
```

---

### 2. **CSV Data: Realtor Listings**

**Problem:**
- Rough Quarters reads CSVs from `experiments/` directory
- Data not in database, hard to query

**Solution: Import to Vayo**

**Create Vayo scraper:**
```javascript
// vayo/stuy-scrape-csv/scrapers/import-realtor-csv.js

const Database = require('better-sqlite3');
const fs = require('fs');
const csv = require('csv-parse/sync');

// Read manhattan_all_listings.csv
// Parse and insert into stuytown.db
// Add to existing 'craigslist_listings' table (rename to 'listings')
// Or create new 'realtor_listings' table
```

**Update Rough Quarters:**
```python
# strategies/realtor_listings.py
from core.vayo_client import VayoClient

class RealtorListingsStrategy:
    def search(self):
        vayo = VayoClient()
        listings = vayo.get_current_listings(source='realtor')
        # Process
```

---

### 3. **Query Strategies (Keep as-is)**

These are fine - they just query existing data:

âœ… `discover_great_buildings.py` - Queries Vayo DB (good!)
âœ… `well_maintained_buildings.py` - Queries HPD data
âœ… `long_tenure_simple.py` - Queries ACRIS
âœ… `adjacent_units.py` - Static analysis

**No changes needed** - just ensure they use VayoClient

---

## ğŸ“‹ Migration Checklist

### Phase 1: Consolidate Reddit Scraping (Priority 1)

- [ ] **Document Vayo's Reddit scraper**
  - What it scrapes (subreddits, search terms)
  - Database schema (where it saves)
  - How to run it

- [ ] **Add Rough Quarters search terms to Vayo**
  - Current: Vayo scrapes r/NYCApartments for rentals
  - Add: Building testimonials, "lived there loved it" searches
  - Save to database with tags for rough-quarters usage

- [ ] **Create Vayo table for testimonials**
  ```sql
  CREATE TABLE reddit_testimonials (
    id INTEGER PRIMARY KEY,
    building_name TEXT,
    address TEXT,
    bin TEXT,
    post_id TEXT,
    subreddit TEXT,
    title TEXT,
    body TEXT,
    sentiment TEXT,  -- 'positive', 'negative', 'neutral'
    posted_date DATE,
    scraped_date DATE,
    source_url TEXT,
    tags TEXT,  -- JSON: ['rough-quarters', 'building-review', etc.]
    FOREIGN KEY (bin) REFERENCES buildings(bin)
  );
  ```

- [ ] **Update Vayo scraper to populate new table**
  ```javascript
  // scrape-reddit.js - add testimonial extraction
  // When finding posts about buildings, insert into reddit_testimonials
  ```

- [ ] **Create VayoClient method**
  ```python
  def get_building_testimonials(self, building_name=None, bin=None):
      """Get Reddit testimonials from Vayo DB"""
  ```

- [ ] **Update Rough Quarters strategies**
  - Replace scraping code with VayoClient queries
  - Test that it finds same data

- [ ] **Delete duplicate Python scrapers**
  - Archive old code (just in case)
  - Remove from active strategies

---

### Phase 2: Import Realtor Data to Vayo (Priority 2)

- [ ] **Decide database schema**
  - Option A: Add to existing `craigslist_listings` (rename to `listings`)
  - Option B: Create separate `realtor_listings` table
  - **Recommendation:** Option A (unified listings table)

- [ ] **Update listings table schema**
  ```sql
  ALTER TABLE craigslist_listings RENAME TO listings;

  -- Add source tracking
  ALTER TABLE listings ADD COLUMN data_source TEXT DEFAULT 'craigslist';
  -- 'craigslist', 'reddit', 'realtor', 'streeteasy', etc.
  ```

- [ ] **Create CSV import script**
  ```javascript
  // vayo/stuy-scrape-csv/scrapers/import-realtor-csv.js
  // Read experiments/*.csv
  // Parse, normalize, insert into listings table
  ```

- [ ] **Move CSV files to Vayo**
  ```bash
  mv rough-quarters/experiments/*.csv vayo/data/raw/
  ```

- [ ] **Run import**
  ```bash
  node scrapers/import-realtor-csv.js
  ```

- [ ] **Update VayoClient**
  ```python
  def get_current_listings(self, source=None, building_address=None):
      """Get listings from Vayo DB, optionally filter by source"""
  ```

- [ ] **Update Rough Quarters strategy**
  - Use VayoClient instead of reading CSV

---

### Phase 3: Documentation (Priority 3)

- [ ] **Create Vayo README**
  - What Vayo is (NYC real estate data hub)
  - What it scrapes
  - Database schema
  - How to add new scrapers
  - How other projects can use it

- [ ] **Create Rough Quarters docs**
  - How it uses Vayo
  - VayoClient API reference
  - Adding new strategies (when to scrape vs query)

- [ ] **Create shared data dictionary**
  - All tables in stuytown.db
  - Column definitions
  - Relationships
  - Example queries

- [ ] **Architecture diagram**
  - Visual showing Vayo â†’ Rough Quarters flow
  - Where scrapers live
  - Where data lives
  - Who queries what

---

## ğŸ—ï¸ Proposed Vayo Structure (After Migration)

```
/Users/pjump/Desktop/projects/vayo/
â”‚
â”œâ”€â”€ README.md                           â† Document the data hub
â”‚   - What Vayo is
â”‚   - How to use it
â”‚   - How to contribute scrapers
â”‚
â”œâ”€â”€ stuy-scrape-csv/                    â† Main data hub
â”‚   â”‚
â”‚   â”œâ”€â”€ stuytown.db                     â† 30GB single source of truth
â”‚   â”‚
â”‚   â”œâ”€â”€ scrapers/                       â† ALL scrapers here
â”‚   â”‚   â”œâ”€â”€ scrape-reddit.js            âœ… Existing
â”‚   â”‚   â”œâ”€â”€ scrape-streeteasy.js        âœ… Existing
â”‚   â”‚   â”œâ”€â”€ scrape-craigslist.js        âœ… Existing
â”‚   â”‚   â”œâ”€â”€ scrape-facebook.js          âœ… Existing
â”‚   â”‚   â”œâ”€â”€ import-realtor-csv.js       â† NEW: Import Realtor data
â”‚   â”‚   â””â”€â”€ scrape-zillow.js            â† FUTURE: Zillow scraper
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                           â† Raw data storage
â”‚   â”‚   â””â”€â”€ raw/
â”‚   â”‚       â”œâ”€â”€ manhattan_all_listings.csv  â† Moved from rough-quarters
â”‚   â”‚       â””â”€â”€ brooklyn_all_listings.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ docs/                           â† Documentation
â”‚   â”‚   â”œâ”€â”€ DATABASE_SCHEMA.md          â† NEW: All tables documented
â”‚   â”‚   â”œâ”€â”€ SCRAPER_GUIDE.md            â† NEW: How to add scrapers
â”‚   â”‚   â””â”€â”€ API_REFERENCE.md            â† NEW: VayoClient methods
â”‚   â”‚
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ geocode-listings.js         â† Shared utility
â”‚       â””â”€â”€ generate-carfax.js          â† Vayo-specific (RentIntel)
â”‚
â””â”€â”€ server.js                           â† RentIntel web UI
```

---

## ğŸ“Š Data Flow (After Migration)

```
EXTERNAL SOURCES
â”œâ”€â”€ Reddit API
â”œâ”€â”€ Craigslist
â”œâ”€â”€ StreetEasy
â”œâ”€â”€ Realtor.com CSVs
â”œâ”€â”€ NYC Open Data
â””â”€â”€ Facebook Marketplace
    â†“
VAYO SCRAPERS (Single location)
â”œâ”€â”€ scrape-reddit.js           â†’ reddit_testimonials table
â”œâ”€â”€ import-realtor-csv.js      â†’ listings table
â”œâ”€â”€ scrape-streeteasy.js       â†’ listings table
â””â”€â”€ (7+ scrapers)
    â†“
VAYO DATABASE (stuytown.db - 30GB)
â”œâ”€â”€ buildings (571K)
â”œâ”€â”€ complaints (26M HPD)
â”œâ”€â”€ listings (Realtor + Craigslist + Reddit + StreetEasy)
â”œâ”€â”€ reddit_testimonials (NEW)
â”œâ”€â”€ acris_real_property (16M)
â””â”€â”€ 36+ tables
    â†“
VAYO CLIENT (Query Interface)
â”œâ”€â”€ get_buildings()
â”œâ”€â”€ get_building_testimonials()
â”œâ”€â”€ get_current_listings()
â”œâ”€â”€ get_rental_history()
â””â”€â”€ get_building_health_score()
    â†“
CONSUMING PROJECTS
â”œâ”€â”€ Vayo/RentIntel (Carfax for apartments)
â”œâ”€â”€ Rough Quarters (Diamond discovery)
â””â”€â”€ Future projects (reuse same data)
```

---

## ğŸ¯ Success Criteria

After migration, we should have:

âœ… **Zero duplicate scrapers**
- Reddit: Only in Vayo
- Realtor: Only in Vayo
- All scraping in one place

âœ… **Single database**
- All data in stuytown.db
- No CSV files being read directly
- Clean query interface

âœ… **Clear documentation**
- README for Vayo (what it is)
- README for Rough Quarters (how to use)
- Database schema documented
- VayoClient API documented

âœ… **Working data flow**
- Vayo scrapers run â†’ populate DB
- Rough Quarters queries â†’ finds data
- Both projects work independently

âœ… **Reusable infrastructure**
- Future projects can use Vayo
- Easy to add new scrapers
- Clean separation of concerns

---

## ğŸ“ Next Steps

1. **Review this audit** - Make sure architecture makes sense
2. **Approve migration plan** - Any changes needed?
3. **Start Phase 1** - Consolidate Reddit scraping
4. **Document as we go** - Create docs in parallel
5. **Test thoroughly** - Ensure nothing breaks

---

**Ready to start the migration?** We'll do it incrementally with full documentation.
